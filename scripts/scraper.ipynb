{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining jupyter-testing from git+https://github.com/gauravmm/jupyter-testing.git#egg=jupyter-testing\n",
      "  Updating ./src/jupyter-testing clone\n",
      "  Running command git fetch -q --tags\n",
      "  Running command git reset --hard -q 8c6b703e663a16f77af53a05096f0258274656b2\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: jupyter-testing\n",
      "  Attempting uninstall: jupyter-testing\n",
      "    Found existing installation: jupyter-testing 0.0.2\n",
      "    Uninstalling jupyter-testing-0.0.2:\n",
      "      Successfully uninstalled jupyter-testing-0.0.2\n",
      "  Running setup.py develop for jupyter-testing\n",
      "Successfully installed jupyter-testing-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -e git+https://github.com/gauravmm/jupyter-testing.git#egg=jupyter-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The scraper notebook: \n",
    "\n",
    "This notebook contains cells to scrape the needed data. There are two major tasks in this notebook. \n",
    "1. For each of the four genres, 1250 books and their attributes (e.g. book title, book author) are collected. \n",
    "2. For the fiction genre, as many reviews are collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup library imports\n",
    "# For now the requests library will not be used since we are collecting the data manually\n",
    "# import requests\n",
    "\n",
    "import os \n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from testing.testing import test\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Collecting book attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/md/2rk3mn0j56b3nm53qc4_7hzr0000gn/T/ipykernel_26843/714183448.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mroots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "def get_html_test(get_html): \n",
    "#     file_path = \"../HTML/Fiction\"\n",
    "    file_path = \"../HTML/Science\"\n",
    "    # file_path = \"../HTML/Religion\"\n",
    "    # file_path = \"../HTML/Crime\"\n",
    "\n",
    "    roots = get_html(file_path)\n",
    "\n",
    "    num_pages = 25\n",
    "    \n",
    "    test.equal(len(roots), num_pages)\n",
    "    test.equal(isinstance(roots, list), True)\n",
    "    test.equal(all(isinstance(root, bs4.BeautifulSoup) for root in roots), True)\n",
    "\n",
    "@test\n",
    "def get_html(file_path): \n",
    "    \"\"\"\n",
    "    Retrieve ALL the html pages on goodreads for given genre.\n",
    "\n",
    "    Returns:\n",
    "        roots (list): list of bs4 objects for html file\n",
    "    \"\"\"\n",
    "    lst_html = list()\n",
    "    roots = list()\n",
    "\n",
    "    \n",
    "    for filename in sorted(os.listdir(file_path)):\n",
    "        with open(os.path.join(file_path, filename)) as f:\n",
    "            content = f.read()\n",
    "            lst_html.append(content)\n",
    "\n",
    "    for html_page in lst_html: \n",
    "        # response.text (string): String of HTML corresponding to a page of 50 books\n",
    "        root = BeautifulSoup(html_page, 'html.parser')        \n",
    "        roots.append(root)\n",
    "\n",
    "    return roots\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page_test(parse_page):\n",
    "    file_path = \"../HTML/Fiction\"\n",
    "    # file_path = \"../HTML/Science\"\n",
    "    # file_path = \"../HTML/Religion\"\n",
    "    # file_path = \"../HTML/Crime\"\n",
    "\n",
    "    roots = get_html(file_path)\n",
    "    \n",
    "    book_attributes = parse_page(roots)\n",
    "\n",
    "\n",
    "    book_per_page = 50\n",
    "    num_pages = 25 \n",
    "    expected_total = book_per_page * num_pages\n",
    "\n",
    "    test.true(len(book_attributes) == 9)\n",
    "    [test.equal(len(attribute), expected_total) for attribute in book_attributes]\n",
    "\n",
    "\n",
    "# @test\n",
    "def parse_page(roots):\n",
    "    \"\"\"\n",
    "    Parse the reviews on each of the 25 pages.\n",
    "    \n",
    "    Args:\n",
    "        book_attributes (list): book_title, author_name, ratings, num_of_ratings, date_published\n",
    "\n",
    "    Returns:\n",
    "        book_attributes (list) : \n",
    "        - book_url, book_title, author_name, ratings, num_of_ratings, date_published\n",
    "    \"\"\"\n",
    "    \n",
    "    book_id, book_url, book_title, author_name, ratings, num_of_ratings, date_published, book_shelved, book_genre = list(), list(), list(), list(), list(), list(), list(), list(), list()\n",
    "    book_attributes = list()\n",
    "\n",
    "    for root in roots:\n",
    "        book_link_prefix = \"https://www.goodreads.com\"\n",
    "        book_url_page = [x['href'] for x in root.find_all(\"a\", class_=\"bookTitle\")]\n",
    "        \n",
    "        book_id_page = [book_link.split(\"/book/show/\")[1].split(\".\")[0] for book_link in book_url_page]\n",
    "        book_id.extend(book_id_page)\n",
    "\n",
    "        book_url_page = [book_link_prefix+book_link for book_link in book_url_page]\n",
    "        book_url.extend(book_url_page)\n",
    "        \n",
    "        book_title_page = [x.get_text() for x in root.find_all(\"a\", class_=\"bookTitle\")]\n",
    "        book_title.extend(book_title_page)\n",
    "\n",
    "        author_name_page = [x.get_text() for x in root.find_all(\"a\", class_=\"authorName\")]\n",
    "        author_name.extend(author_name_page)\n",
    "\n",
    "        ratings_data = []\n",
    "        shevles_genre_data = []\n",
    "\n",
    "        for div in root.find_all(\"div\", class_=\"left\"):\n",
    "            start = 'shelved'\n",
    "            end = 'avg rating'\n",
    "            s = div.get_text()\n",
    "            shevles_genre_data = s[s.find(start)+len(start):s.rfind(end)]\n",
    "\n",
    "            keyword = \" times as \"\n",
    "            before_keyword, keyword, after_keyword = shevles_genre_data.partition(keyword)\n",
    "            book_shelved.append(int(before_keyword))\n",
    "            book_genre.append(after_keyword.split()[0][:-1])\n",
    "            \n",
    "\n",
    "        for div in root.find_all(\"div\", class_=\"left\"):\n",
    "            for span in div.find_all('span', {'class' : 'greyText smallText'}):\n",
    "                ratings_data.append(span.get_text())\n",
    "        \n",
    "        for elem in ratings_data: \n",
    "\n",
    "            ratings.append(elem.split()[2])\n",
    "            num_of_ratings.append(elem.split()[4])\n",
    "            \n",
    "            # If date published is not given pass in nan value\n",
    "            if len(elem.split()) < 9: \n",
    "                date_published.append(np.nan)\n",
    "            else: \n",
    "                date_published.append(elem.split()[8])\n",
    "\n",
    "    book_attributes = [book_id, book_url, book_title, author_name, ratings, num_of_ratings, date_published, book_shelved, book_genre]\n",
    "    \n",
    "    return book_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/md/2rk3mn0j56b3nm53qc4_7hzr0000gn/T/ipykernel_26843/235394824.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_attributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "def create_dataframe_test(create_dataframe):\n",
    "#     file_path = \"../HTML/Fiction\"\n",
    "    file_path = \"../HTML/Science\"\n",
    "    # file_path = \"../HTML/Religion\"\n",
    "    # file_path = \"../HTML/Crime\"\n",
    "\n",
    "    roots = get_html(file_path)\n",
    "    \n",
    "    book_attributes = parse_page(roots)\n",
    "    \n",
    "    df = create_dataframe(book_attributes)\n",
    "    \n",
    "    test.equal(len(df.columns), len(book_attributes)) \n",
    "    test.equal(isinstance(df, pd.DataFrame), True) \n",
    "    # TODO: check row and column values\n",
    "\n",
    "    \n",
    "        \n",
    "@test\n",
    "def create_dataframe(book_attributes):\n",
    "    \"\"\"\n",
    "    Create a dataframe\n",
    "    \n",
    "    Args:\n",
    "        book_attributes (list): book_title, author_name, ratings, num_of_ratings, date_published\n",
    "        \n",
    "    Returns:\n",
    "        df (pd.DataFrame) : \n",
    "        - Columns: book_title, author_name, ratings, num_of_ratings, date_published\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {'book_id': book_attributes[0],\n",
    "        'book_url': book_attributes[1],\n",
    "        'book_title': book_attributes[2],\n",
    "        'author_name': book_attributes[3],\n",
    "        'ratings': book_attributes[4],\n",
    "        'num_of_ratings': book_attributes[5],\n",
    "        'date_published': book_attributes[6],\n",
    "        'book_shelved': book_attributes[7],\n",
    "        'book_genre': book_attributes[8]\n",
    "        })\n",
    "    \n",
    "\n",
    "    df.to_csv('goodreads_fiction.csv', index=False)  \n",
    "    # df.to_csv('goodreads_science.csv', index=False)  \n",
    "    # df.to_csv('goodreads_religion.csv', index=False)  \n",
    "    # df.to_csv('goodreads_crime.csv', index=False)  \n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Collecting reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F = open(\"IDS.txt\", \"w\")\n",
    "# for line in df[\"book_id\"]:\n",
    "#     F.write(line)\n",
    "#     F.write(\"\\n\")\n",
    "# F.close()\n",
    "\n",
    "# !mkdir book_reviews_folder\n",
    "\n",
    "# !python get_reviews.py --book_ids_path IDS.txt \\\n",
    "# --output_directory_path book_reviews_folder --sort_order default --browser chrome \n",
    "# reviews_df = pd.read_json('book_reviews_folder/all_reviews.json')\n",
    "# reviews_df.to_csv(\"review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d9279c439293cd56693e7c05115c53cbb1633ee63d7052d68a345e17a860490"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
