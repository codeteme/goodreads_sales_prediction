{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -e git+https://github.com/gauravmm/jupyter-testing.git#egg=jupyter-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup library imports\n",
    "import io, time, json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from testing.testing import test\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING get_html: PASSED 3/3\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "def get_html_test(get_html): \n",
    "    roots = get_html()\n",
    "    num_pages = 25\n",
    "    \n",
    "    test.equal(len(roots), num_pages)\n",
    "    test.equal(isinstance(roots, list), True)\n",
    "    test.equal(all(isinstance(root, bs4.BeautifulSoup) for root in roots), True)\n",
    "\n",
    "@test\n",
    "def get_html(): \n",
    "    \"\"\"\n",
    "    Retrieve ALL the html pages on goodreads for fiction genre.\n",
    "\n",
    "    Returns:\n",
    "        roots (list): list of bs4 objects for html file\n",
    "    \"\"\"\n",
    "    lst_html = list()\n",
    "    roots = list()\n",
    "\n",
    "    file_path_fiction = \"../HTML/Fiction\"\n",
    "    for filename in os.listdir(file_path_fiction):\n",
    "        with open(os.path.join(file_path_fiction, filename)) as f:\n",
    "            content = f.read()\n",
    "            lst_html.append(content)\n",
    "            # content = BeautifulSoup(f, 'html.parser')\n",
    "            # roots.append(content)\n",
    "\n",
    "\n",
    "    for html_page in lst_html: \n",
    "        # response.text (string): String of HTML corresponding to a page of 50 books\n",
    "        root = BeautifulSoup(html_page, 'html.parser')        \n",
    "        roots.append(root)\n",
    "\n",
    "    return roots\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING parse_page: PASSED 5/5\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_page_test(parse_page):\n",
    "    roots = get_html()\n",
    "    book_attributes = parse_page(roots)\n",
    "\n",
    "\n",
    "    book_per_page = 50\n",
    "    num_pages = 25 \n",
    "    expected_total = book_per_page * num_pages\n",
    "\n",
    "    test.true(len(book_attributes[0]) == expected_total)\n",
    "    test.true(len(book_attributes[1]) == expected_total)\n",
    "    test.true(len(book_attributes[2]) == expected_total)\n",
    "    test.true(len(book_attributes[3]) == expected_total)\n",
    "    test.true(len(book_attributes[4]) == expected_total)\n",
    "\n",
    "\n",
    "\n",
    "@test\n",
    "def parse_page(roots):\n",
    "    \"\"\"\n",
    "    Parse the reviews on each of the 25 pages.\n",
    "    \n",
    "    Args:\n",
    "        book_attributes (list): book_titles, author_name, ratings, num_of_ratings, date_published\n",
    "\n",
    "    Returns:\n",
    "        book_attributes (list) : \n",
    "        - book_titles, author_name, ratings, num_of_ratings, date_published\n",
    "    \"\"\"\n",
    "    \n",
    "    book_titles = list()\n",
    "    author_name = list()\n",
    "    ratings = list()\n",
    "    num_of_ratings = list()\n",
    "    date_published = list()\n",
    "\n",
    "    for root in roots: \n",
    "        book_title_page = [x.get_text() for x in root.find_all(\"a\", class_=\"bookTitle\")]\n",
    "        book_titles.extend(book_title_page)\n",
    "        author_name_page = [x.get_text() for x in root.find_all(\"a\", class_=\"authorName\")]\n",
    "        author_name.extend(author_name_page)\n",
    "\n",
    "        ratings_data = []\n",
    "\n",
    "        for div in root.find_all(\"div\", class_=\"left\"):\n",
    "            for span in div.find_all('span', {'class' : 'greyText smallText'}):\n",
    "                ratings_data.append(span.get_text())\n",
    "\n",
    "        for elem in ratings_data: \n",
    "            ratings.append(elem.split()[2])\n",
    "            num_of_ratings.append(elem.split()[4])\n",
    "            date_published.append(elem.split()[8])\n",
    "            \n",
    "    book_attributes = [book_titles, author_name, ratings, num_of_ratings, date_published]\n",
    "    \n",
    "    return book_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TESTING create_dataframe: PASSED 2/2\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_dataframe_test(create_dataframe):\n",
    "    roots = get_html()\n",
    "    book_attributes = parse_page(roots)\n",
    "    df = create_dataframe(book_attributes)\n",
    "    \n",
    "    test.equal(len(df.columns), 5) \n",
    "    test.equal(isinstance(df, pd.DataFrame), True) \n",
    "    # TODO: check row and column values\n",
    "\n",
    "    \n",
    "        \n",
    "@test\n",
    "def create_dataframe(book_attributes):\n",
    "    \"\"\"\n",
    "    Create a dataframe\n",
    "    \n",
    "    Args:\n",
    "        book_attributes (list): book_titles, author_name, ratings, num_of_ratings, date_published\n",
    "        \n",
    "    Returns:\n",
    "        df (pd.DataFrame) : \n",
    "        - Columns: book_titles, author_name, ratings, num_of_ratings, date_published\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {'book_title': book_attributes[0],\n",
    "        'author_name': book_attributes[1],\n",
    "        'ratings': book_attributes[2],\n",
    "        'num_of_ratings': book_attributes[3],\n",
    "        'date_published': book_attributes[4]\n",
    "        })\n",
    "    \n",
    "\n",
    "    df.to_csv('goodreads.csv', index=False,)  \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d9279c439293cd56693e7c05115c53cbb1633ee63d7052d68a345e17a860490"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('csx433env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
