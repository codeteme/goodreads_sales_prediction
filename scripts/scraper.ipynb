{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#The-scraper-notebook:\" data-toc-modified-id=\"The-scraper-notebook:-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>The scraper notebook:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Task-1:-Collecting-book-attributes\" data-toc-modified-id=\"Task-1:-Collecting-book-attributes-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Task 1: Collecting book attributes</a></span></li><li><span><a href=\"#Task-2:-Collecting-reviews\" data-toc-modified-id=\"Task-2:-Collecting-reviews-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Task 2: Collecting reviews</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The scraper notebook: \n",
    "\n",
    "This notebook contains cells to scrape the needed data. There are two major tasks in this notebook. \n",
    "1. For each of the four genres, 1250 books and their attributes (e.g. book title, book author) are collected. \n",
    "2. For the fiction genre, as many reviews are collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all the requirement packages and the testing package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -e git+https://github.com/gauravmm/jupyter-testing.git#egg=jupyter-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (4.10.0)\n",
      "Requirement already satisfied: selenium in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (4.1.0)\n",
      "Requirement already satisfied: lxml in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (4.6.3)\n",
      "Requirement already satisfied: geckodriver-autoinstaller in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (0.1.0)\n",
      "Requirement already satisfied: chromedriver-py in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (95.0.4638.17)\n",
      "Requirement already satisfied: pandas in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.3.4)\n",
      "Requirement already satisfied: regex in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (2021.8.3)\n",
      "Requirement already satisfied: credentials in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->-r requirements.txt (line 1)) (2.3.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from selenium->-r requirements.txt (line 2)) (0.9.2)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from selenium->-r requirements.txt (line 2)) (1.26.7)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from selenium->-r requirements.txt (line 2)) (0.19.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 6)) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 6)) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 2)) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 2)) (21.2.0)\n",
      "Requirement already satisfied: sniffio in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 2)) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 2)) (3.2)\n",
      "Requirement already satisfied: outcome in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from urllib3[secure]~=1.26->selenium->-r requirements.txt (line 2)) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from urllib3[secure]~=1.26->selenium->-r requirements.txt (line 2)) (3.4.8)\n",
      "Requirement already satisfied: certifi in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from urllib3[secure]~=1.26->selenium->-r requirements.txt (line 2)) (2021.10.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium->-r requirements.txt (line 2)) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium->-r requirements.txt (line 2)) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/zhijie/opt/anaconda3/lib/python3.8/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->-r requirements.txt (line 2)) (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup library imports\n",
    "# For now the requests library will not be used since we are collecting the data manually\n",
    "# import requests\n",
    "\n",
    "import os \n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from testing.testing import test\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Collecting book attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the BS4 objects from the HTML files that we have collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(file_path): \n",
    "    \"\"\"\n",
    "    Retrieve ALL the html pages on goodreads for given genre.\n",
    "\n",
    "    Returns:\n",
    "        roots (list): list of bs4 objects for html file\n",
    "    \"\"\"\n",
    "    lst_html = list()\n",
    "    roots = list()\n",
    "\n",
    "    \n",
    "    for filename in sorted(os.listdir(file_path)):\n",
    "        with open(os.path.join(file_path, filename)) as f:\n",
    "            content = f.read()\n",
    "            lst_html.append(content)\n",
    "\n",
    "    for html_page in lst_html: \n",
    "        # response.text (string): String of HTML corresponding to a page of 50 books\n",
    "        root = BeautifulSoup(html_page, 'html.parser')        \n",
    "        roots.append(root)\n",
    "\n",
    "    return roots\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the information in the HTML file. `book_id`, `book_url`, `book_title`, `author_name`, `ratings`, `num_of_ratings`, `date_published`, `book_shelved`, `book_genre` are placed into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page(roots):\n",
    "    \"\"\"\n",
    "    Parse the reviews on each of the 25 pages.\n",
    "    \n",
    "    Args:\n",
    "        book_attributes (list): book_title, author_name, ratings, num_of_ratings, date_published\n",
    "\n",
    "    Returns:\n",
    "        book_attributes (list) : \n",
    "        - book_url, book_title, author_name, ratings, num_of_ratings, date_published\n",
    "    \"\"\"\n",
    "    \n",
    "    book_id, book_url, book_title, author_name, ratings, num_of_ratings, date_published, book_shelved, book_genre = list(), list(), list(), list(), list(), list(), list(), list(), list()\n",
    "    book_attributes = list()\n",
    "\n",
    "    for root in roots:\n",
    "        book_link_prefix = \"https://www.goodreads.com\"\n",
    "        book_url_page = [x['href'] for x in root.find_all(\"a\", class_=\"bookTitle\")]\n",
    "        \n",
    "        book_id_page = [book_link.split(\"/book/show/\")[1].split(\".\")[0] for book_link in book_url_page]\n",
    "        book_id.extend(book_id_page)\n",
    "\n",
    "        book_url_page = [book_link_prefix+book_link for book_link in book_url_page]\n",
    "        book_url.extend(book_url_page)\n",
    "        \n",
    "        book_title_page = [x.get_text() for x in root.find_all(\"a\", class_=\"bookTitle\")]\n",
    "        book_title.extend(book_title_page)\n",
    "\n",
    "        author_name_page = [x.get_text() for x in root.find_all(\"a\", class_=\"authorName\")]\n",
    "        author_name.extend(author_name_page)\n",
    "\n",
    "        ratings_data = []\n",
    "        shevles_genre_data = []\n",
    "\n",
    "        for div in root.find_all(\"div\", class_=\"left\"):\n",
    "            start = 'shelved'\n",
    "            end = 'avg rating'\n",
    "            s = div.get_text()\n",
    "            shevles_genre_data = s[s.find(start)+len(start):s.rfind(end)]\n",
    "\n",
    "            keyword = \" times as \"\n",
    "            before_keyword, keyword, after_keyword = shevles_genre_data.partition(keyword)\n",
    "            book_shelved.append(int(before_keyword))\n",
    "            book_genre.append(after_keyword.split()[0][:-1])\n",
    "            \n",
    "\n",
    "        for div in root.find_all(\"div\", class_=\"left\"):\n",
    "            for span in div.find_all('span', {'class' : 'greyText smallText'}):\n",
    "                ratings_data.append(span.get_text())\n",
    "        \n",
    "        for elem in ratings_data: \n",
    "\n",
    "            ratings.append(elem.split()[2])\n",
    "            num_of_ratings.append(elem.split()[4])\n",
    "            \n",
    "            # If date published is not given pass in nan value\n",
    "            if len(elem.split()) < 9: \n",
    "                date_published.append(np.nan)\n",
    "            else: \n",
    "                date_published.append(elem.split()[8])\n",
    "\n",
    "    book_attributes = [book_id, book_url, book_title, author_name, ratings, num_of_ratings, date_published, book_shelved, book_genre]\n",
    "    \n",
    "    return book_attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the list we have to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(book_attributes):\n",
    "    \"\"\"\n",
    "    Create a dataframe\n",
    "    \n",
    "    Args:\n",
    "        book_attributes (list): book_title, author_name, ratings, num_of_ratings, date_published\n",
    "        \n",
    "    Returns:\n",
    "        df (pd.DataFrame) : \n",
    "        - Columns: book_title, author_name, ratings, num_of_ratings, date_published\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {'book_id': book_attributes[0],\n",
    "        'book_url': book_attributes[1],\n",
    "        'book_title': book_attributes[2],\n",
    "        'author_name': book_attributes[3],\n",
    "        'ratings': book_attributes[4],\n",
    "        'num_of_ratings': book_attributes[5],\n",
    "        'date_published': book_attributes[6],\n",
    "        'book_shelved': book_attributes[7],\n",
    "        'book_genre': book_attributes[8]\n",
    "        })\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function above to get dataframes of different genres, and then save them as separate csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['../HTML/Fiction', '../HTML/Science', '../HTML/Religion', '../HTML/Crime']\n",
    "for file_path in file_paths: \n",
    "    roots = get_html(file_path)\n",
    "    book_attributes = parse_page(roots)\n",
    "    df = create_dataframe(book_attributes)\n",
    "    filename = 'goodreads_' + file_path.split('/')[-1] + '.csv'\n",
    "    df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Collecting reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second part of the scapper is to collect the reviews for each book. We modified some external code from <https://github.com/maria-antoniak/goodreads-scraper>. The logic of the scapper is to use the Chrome driver to open the book url and then read the reviews from the page.\n",
    "At the beginning, we wrote code to scrap the review. However, we found the Browser will be blocked or raise a login page which prevent us to scrap the page. After modify the external code. We succuessfuly extract around 294,000 reviews for 1250 fiction books. In order to complete the task, we sacrificed some of the data by reducing the time interval and num of re-scrapping. It is due to 3 scapper prevention techniques on the website.\n",
    "1. The page will give duplicate reviews if the time interval is too short.\n",
    "2. The login panel will pop out, which prevent the scrapper from reading the information\n",
    "3. After scrapped about 5 books, the webpage will suspend the connection for around 10 sec.\n",
    "\n",
    "All of these costed us around 20 hrs to collect the dataset with missing data and duplicate information. The further data wrangling and visualization will be shown in another notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe below is the one we have collected for fiction books with basic info. In this case, we created a file containing all the `book_ids`. This file will be read by the python document called `get_reviews.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>book_url</th>\n",
       "      <th>book_title</th>\n",
       "      <th>author_name</th>\n",
       "      <th>ratings</th>\n",
       "      <th>num_of_ratings</th>\n",
       "      <th>date_published</th>\n",
       "      <th>book_shelved</th>\n",
       "      <th>book_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2657.To_Kill_a_Mockingbird</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "      <td>To Kill a Mockingbird (Paperback)</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.27</td>\n",
       "      <td>5,025,333</td>\n",
       "      <td>1960</td>\n",
       "      <td>24464</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40961427-1984</td>\n",
       "      <td>https://www.goodreads.com/book/show/40961427-1984</td>\n",
       "      <td>1984 (Kindle Edition)</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3,609,831</td>\n",
       "      <td>1949</td>\n",
       "      <td>24368</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4671.The_Great_Gatsby</td>\n",
       "      <td>https://www.goodreads.com/book/show/4671.The_G...</td>\n",
       "      <td>The Great Gatsby (Paperback)</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4,217,051</td>\n",
       "      <td>1925</td>\n",
       "      <td>22232</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170448.Animal_Farm</td>\n",
       "      <td>https://www.goodreads.com/book/show/170448.Ani...</td>\n",
       "      <td>Animal Farm (Mass Market Paperback)</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>3.97</td>\n",
       "      <td>3,105,131</td>\n",
       "      <td>1945</td>\n",
       "      <td>20400</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.Harry_Potter_and_the_Sorcerer_s_Stone</td>\n",
       "      <td>https://www.goodreads.com/book/show/3.Harry_Po...</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.47</td>\n",
       "      <td>8,031,019</td>\n",
       "      <td>1997</td>\n",
       "      <td>20064</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>7278752-dolores-claiborne</td>\n",
       "      <td>https://www.goodreads.com/book/show/7278752-do...</td>\n",
       "      <td>Dolores Claiborne (ebook)</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>3.89</td>\n",
       "      <td>135,428</td>\n",
       "      <td>1992</td>\n",
       "      <td>1241</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>99300.The_Yellow_Wallpaper_and_Other_Stories</td>\n",
       "      <td>https://www.goodreads.com/book/show/99300.The_...</td>\n",
       "      <td>The Yellow Wallpaper and Other Stories (Paperb...</td>\n",
       "      <td>Charlotte Perkins Gilman</td>\n",
       "      <td>4.05</td>\n",
       "      <td>83,538</td>\n",
       "      <td>1892</td>\n",
       "      <td>1241</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>10628.Night_Shift</td>\n",
       "      <td>https://www.goodreads.com/book/show/10628.Nigh...</td>\n",
       "      <td>Night Shift (Paperback)</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>4.02</td>\n",
       "      <td>157,161</td>\n",
       "      <td>1978</td>\n",
       "      <td>1240</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>2547.The_Prophet</td>\n",
       "      <td>https://www.goodreads.com/book/show/2547.The_P...</td>\n",
       "      <td>The Prophet (Paperback)</td>\n",
       "      <td>Kahlil Gibran</td>\n",
       "      <td>4.21</td>\n",
       "      <td>261,164</td>\n",
       "      <td>1923</td>\n",
       "      <td>1240</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>7664041-inheritance</td>\n",
       "      <td>https://www.goodreads.com/book/show/7664041-in...</td>\n",
       "      <td>Inheritance (The Inheritance Cycle, #4)</td>\n",
       "      <td>Christopher Paolini</td>\n",
       "      <td>4.09</td>\n",
       "      <td>243,602</td>\n",
       "      <td>2011</td>\n",
       "      <td>1238</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           book_id  \\\n",
       "0                       2657.To_Kill_a_Mockingbird   \n",
       "1                                    40961427-1984   \n",
       "2                            4671.The_Great_Gatsby   \n",
       "3                               170448.Animal_Farm   \n",
       "4          3.Harry_Potter_and_the_Sorcerer_s_Stone   \n",
       "...                                            ...   \n",
       "1245                     7278752-dolores-claiborne   \n",
       "1246  99300.The_Yellow_Wallpaper_and_Other_Stories   \n",
       "1247                             10628.Night_Shift   \n",
       "1248                              2547.The_Prophet   \n",
       "1249                           7664041-inheritance   \n",
       "\n",
       "                                               book_url  \\\n",
       "0     https://www.goodreads.com/book/show/2657.To_Ki...   \n",
       "1     https://www.goodreads.com/book/show/40961427-1984   \n",
       "2     https://www.goodreads.com/book/show/4671.The_G...   \n",
       "3     https://www.goodreads.com/book/show/170448.Ani...   \n",
       "4     https://www.goodreads.com/book/show/3.Harry_Po...   \n",
       "...                                                 ...   \n",
       "1245  https://www.goodreads.com/book/show/7278752-do...   \n",
       "1246  https://www.goodreads.com/book/show/99300.The_...   \n",
       "1247  https://www.goodreads.com/book/show/10628.Nigh...   \n",
       "1248  https://www.goodreads.com/book/show/2547.The_P...   \n",
       "1249  https://www.goodreads.com/book/show/7664041-in...   \n",
       "\n",
       "                                             book_title  \\\n",
       "0                     To Kill a Mockingbird (Paperback)   \n",
       "1                                 1984 (Kindle Edition)   \n",
       "2                          The Great Gatsby (Paperback)   \n",
       "3                   Animal Farm (Mass Market Paperback)   \n",
       "4     Harry Potter and the Sorcerer's Stone (Harry P...   \n",
       "...                                                 ...   \n",
       "1245                          Dolores Claiborne (ebook)   \n",
       "1246  The Yellow Wallpaper and Other Stories (Paperb...   \n",
       "1247                            Night Shift (Paperback)   \n",
       "1248                            The Prophet (Paperback)   \n",
       "1249            Inheritance (The Inheritance Cycle, #4)   \n",
       "\n",
       "                   author_name ratings num_of_ratings date_published  \\\n",
       "0                   Harper Lee    4.27      5,025,333           1960   \n",
       "1                George Orwell    4.19      3,609,831           1949   \n",
       "2          F. Scott Fitzgerald    3.93      4,217,051           1925   \n",
       "3                George Orwell    3.97      3,105,131           1945   \n",
       "4                 J.K. Rowling    4.47      8,031,019           1997   \n",
       "...                        ...     ...            ...            ...   \n",
       "1245              Stephen King    3.89        135,428           1992   \n",
       "1246  Charlotte Perkins Gilman    4.05         83,538           1892   \n",
       "1247              Stephen King    4.02        157,161           1978   \n",
       "1248             Kahlil Gibran    4.21        261,164           1923   \n",
       "1249       Christopher Paolini    4.09        243,602           2011   \n",
       "\n",
       "      book_shelved book_genre  \n",
       "0            24464    fiction  \n",
       "1            24368    fiction  \n",
       "2            22232    fiction  \n",
       "3            20400    fiction  \n",
       "4            20064    fiction  \n",
       "...            ...        ...  \n",
       "1245          1241    fiction  \n",
       "1246          1241    fiction  \n",
       "1247          1240    fiction  \n",
       "1248          1240    fiction  \n",
       "1249          1238    fiction  \n",
       "\n",
       "[1250 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F = open(\"IDS.txt\", \"w\")\n",
    "# for line in df[\"book_id\"]:\n",
    "#     F.write(line)\n",
    "#     F.write(\"\\ndf\")\n",
    "# F.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a review_folder to hold the JSON file for each book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir book_reviews_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the python code and convert the JSON file to a dataframe. And store the dataframe as a csv file, which is called `review.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_reviews.py:273: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=binary_path)\n",
      "2021-11-28 23:30:22.369205 get_reviews.py: Scraping 4708.The_Beautiful_and_Damned...\n",
      "2021-11-28 23:30:22.369246 get_reviews.py: #1222 out of 1250 books\n",
      "Scraped page 1\n",
      "get_reviews.py:173: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  if driver.find_element_by_link_text(str(page_counter)):\n",
      "get_reviews.py:174: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_link_text(str(page_counter)).click()\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "2021-11-28 23:30:35.889118 get_reviews.py: Scraped ✨270✨ reviews for 4708.The_Beautiful_and_Damned\n",
      "=============================\n",
      "2021-11-28 23:30:35.898636 get_reviews.py: Scraping 16255.Tales_of_the_City...\n",
      "2021-11-28 23:30:35.898648 get_reviews.py: #1223 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "get_reviews.py:185: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_link_text(str(9)).click()\n",
      "2021-11-28 23:31:16.668936 get_reviews.py: Scraped ✨210✨ reviews for 16255.Tales_of_the_City\n",
      "=============================\n",
      "2021-11-28 23:31:16.674289 get_reviews.py: Scraping 28954189-scythe...\n",
      "2021-11-28 23:31:16.674302 get_reviews.py: #1224 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "2021-11-28 23:31:31.872289 get_reviews.py: Scraped ✨270✨ reviews for 28954189-scythe\n",
      "=============================\n",
      "2021-11-28 23:31:31.880144 get_reviews.py: Scraping 7234875-the-little-stranger...\n",
      "2021-11-28 23:31:31.880158 get_reviews.py: #1225 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "2021-11-28 23:31:44.909058 get_reviews.py: Scraped ✨240✨ reviews for 7234875-the-little-stranger\n",
      "=============================\n",
      "2021-11-28 23:31:44.917431 get_reviews.py: Scraping 775346.The_Little_Friend...\n",
      "2021-11-28 23:31:44.917443 get_reviews.py: #1226 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "2021-11-28 23:31:57.214573 get_reviews.py: Scraped ✨270✨ reviews for 775346.The_Little_Friend\n",
      "=============================\n",
      "2021-11-28 23:31:57.220942 get_reviews.py: Scraping 14748.Good_in_Bed...\n",
      "2021-11-28 23:31:57.220952 get_reviews.py: #1227 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "2021-11-28 23:32:09.768736 get_reviews.py: Scraped ✨270✨ reviews for 14748.Good_in_Bed\n",
      "=============================\n",
      "2021-11-28 23:32:09.775133 get_reviews.py: Scraping 21104828-the-lake-house...\n",
      "2021-11-28 23:32:09.775146 get_reviews.py: #1228 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "2021-11-28 23:32:23.433120 get_reviews.py: Scraped ✨270✨ reviews for 21104828-the-lake-house\n",
      "=============================\n",
      "2021-11-28 23:32:23.439196 get_reviews.py: Scraping 11761.Underworld...\n",
      "2021-11-28 23:32:23.439205 get_reviews.py: #1229 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "2021-11-28 23:32:36.494062 get_reviews.py: Scraped ✨270✨ reviews for 11761.Underworld\n",
      "=============================\n",
      "2021-11-28 23:32:36.500852 get_reviews.py: Scraping 16054217-the-book-of-life...\n",
      "2021-11-28 23:32:36.500862 get_reviews.py: #1230 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "2021-11-28 23:32:52.998064 get_reviews.py: Scraped ✨270✨ reviews for 16054217-the-book-of-life\n",
      "=============================\n",
      "2021-11-28 23:32:53.004647 get_reviews.py: Scraping 7572.Even_Cowgirls_Get_the_Blues...\n",
      "2021-11-28 23:32:53.004657 get_reviews.py: #1231 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "2021-11-28 23:33:04.516728 get_reviews.py: Scraped ✨240✨ reviews for 7572.Even_Cowgirls_Get_the_Blues\n",
      "=============================\n",
      "2021-11-28 23:33:04.521917 get_reviews.py: Scraping 32969150-stay-with-me...\n",
      "2021-11-28 23:33:04.521927 get_reviews.py: #1232 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "2021-11-28 23:33:14.663141 get_reviews.py: Scraped ✨300✨ reviews for 32969150-stay-with-me\n",
      "=============================\n",
      "2021-11-28 23:33:14.670096 get_reviews.py: Scraping 11438.What_We_Talk_About_When_We_Talk_About_Love...\n",
      "2021-11-28 23:33:14.670107 get_reviews.py: #1233 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "2021-11-28 23:33:28.443196 get_reviews.py: Scraped ✨210✨ reviews for 11438.What_We_Talk_About_When_We_Talk_About_Love\n",
      "=============================\n",
      "2021-11-28 23:33:28.450590 get_reviews.py: Scraping 33311863-american-war...\n",
      "2021-11-28 23:33:28.450604 get_reviews.py: #1234 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 9\n",
      "2021-11-28 23:33:45.246369 get_reviews.py: Scraped ✨240✨ reviews for 33311863-american-war\n",
      "=============================\n",
      "2021-11-28 23:33:45.252648 get_reviews.py: Scraping 89723.The_Lottery_and_Other_Stories...\n",
      "2021-11-28 23:33:45.252659 get_reviews.py: #1235 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "2021-11-28 23:34:00.594110 get_reviews.py: Scraped ✨240✨ reviews for 89723.The_Lottery_and_Other_Stories\n",
      "=============================\n",
      "2021-11-28 23:34:00.603984 get_reviews.py: Scraping 34128219-la-belle-sauvage...\n",
      "2021-11-28 23:34:00.604002 get_reviews.py: #1236 out of 1250 books\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "2021-11-28 23:34:14.650720 get_reviews.py: Scraped ✨240✨ reviews for 34128219-la-belle-sauvage\n",
      "=============================\n",
      "2021-11-28 23:34:14.657889 get_reviews.py: Scraping 15729539-nos4a2...\n",
      "2021-11-28 23:34:14.657901 get_reviews.py: #1237 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "2021-11-28 23:34:35.608991 get_reviews.py: Scraped ✨270✨ reviews for 15729539-nos4a2\n",
      "=============================\n",
      "2021-11-28 23:34:35.617742 get_reviews.py: Scraping 25200.Silence...\n",
      "2021-11-28 23:34:35.617754 get_reviews.py: #1238 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "2021-11-28 23:34:47.646255 get_reviews.py: Scraped ✨270✨ reviews for 25200.Silence\n",
      "=============================\n",
      "2021-11-28 23:34:47.654066 get_reviews.py: Scraping 68494.Perdido_Street_Station...\n",
      "2021-11-28 23:34:47.654077 get_reviews.py: #1239 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 9\n",
      "2021-11-28 23:35:02.377758 get_reviews.py: Scraped ✨240✨ reviews for 68494.Perdido_Street_Station\n",
      "=============================\n",
      "2021-11-28 23:35:02.386362 get_reviews.py: Scraping 23128304-the-strange-library...\n",
      "2021-11-28 23:35:02.386375 get_reviews.py: #1240 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "2021-11-28 23:35:17.165663 get_reviews.py: Scraped ✨270✨ reviews for 23128304-the-strange-library\n",
      "=============================\n",
      "2021-11-28 23:35:17.171740 get_reviews.py: Scraping 38463.If_Beale_Street_Could_Talk...\n",
      "2021-11-28 23:35:17.171749 get_reviews.py: #1241 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "2021-11-28 23:35:28.151917 get_reviews.py: Scraped ✨270✨ reviews for 38463.If_Beale_Street_Could_Talk\n",
      "=============================\n",
      "2021-11-28 23:35:28.160123 get_reviews.py: Scraping 25526296-every-heart-a-doorway...\n",
      "2021-11-28 23:35:28.160136 get_reviews.py: #1242 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 9\n",
      "2021-11-28 23:35:43.695028 get_reviews.py: Scraped ✨240✨ reviews for 25526296-every-heart-a-doorway\n",
      "=============================\n",
      "2021-11-28 23:35:43.703145 get_reviews.py: Scraping 7278752-dolores-claiborne...\n",
      "2021-11-28 23:35:43.703158 get_reviews.py: #1243 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 9\n",
      "2021-11-28 23:35:56.370665 get_reviews.py: Scraped ✨240✨ reviews for 7278752-dolores-claiborne\n",
      "=============================\n",
      "2021-11-28 23:35:56.377383 get_reviews.py: Scraping 99300.The_Yellow_Wallpaper_and_Other_Stories...\n",
      "2021-11-28 23:35:56.377396 get_reviews.py: #1244 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "2021-11-28 23:36:10.073222 get_reviews.py: Scraped ✨270✨ reviews for 99300.The_Yellow_Wallpaper_and_Other_Stories\n",
      "=============================\n",
      "2021-11-28 23:36:10.079787 get_reviews.py: Scraping 10628.Night_Shift...\n",
      "2021-11-28 23:36:10.079800 get_reviews.py: #1245 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 9\n",
      "2021-11-28 23:36:30.163284 get_reviews.py: Scraped ✨210✨ reviews for 10628.Night_Shift\n",
      "=============================\n",
      "2021-11-28 23:36:30.171507 get_reviews.py: Scraping 2547.The_Prophet...\n",
      "2021-11-28 23:36:30.171517 get_reviews.py: #1246 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 6\n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "Scraped page 9\n",
      "Scraped page 10\n",
      "2021-11-28 23:36:41.371127 get_reviews.py: Scraped ✨270✨ reviews for 2547.The_Prophet\n",
      "=============================\n",
      "2021-11-28 23:36:41.377119 get_reviews.py: Scraping 7664041-inheritance...\n",
      "2021-11-28 23:36:41.377128 get_reviews.py: #1247 out of 1250 books\n",
      "Scraped page 1\n",
      "Scraped page 2\n",
      "Scraped page 3\n",
      "Scraped page 4\n",
      "Scraped page 5\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "Scraped page 7\n",
      "Scraped page 8\n",
      "ERROR: StaleElementReferenceException\n",
      "Refreshing Goodreads site and skipping problem page {page_counter} \n",
      "2021-11-28 23:36:59.422398 get_reviews.py: Scraped ✨210✨ reviews for 7664041-inheritance\n",
      "=============================\n",
      "2021-11-28 23:37:14.792441 get_reviews.py:\n",
      "\n",
      "🎉 Success! All book reviews scraped. 🎉\n",
      "\n",
      "Goodreads review files have been output to /book_reviews_folder\n",
      "Goodreads scraping run time = ⏰ 0:06:54.118916 ⏰\n"
     ]
    }
   ],
   "source": [
    "!python get_reviews.py --book_ids_path IDS.txt \\\n",
    "--output_directory_path book_reviews_folder --sort_order default --browser chrome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id_title</th>\n",
       "      <th>book_id</th>\n",
       "      <th>book_title</th>\n",
       "      <th>review_url</th>\n",
       "      <th>review_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_url</th>\n",
       "      <th>text</th>\n",
       "      <th>num_likes</th>\n",
       "      <th>sort_order</th>\n",
       "      <th>shelves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32187419-conversations-with-friends</td>\n",
       "      <td>32187419-conversations-with-friends</td>\n",
       "      <td>Conversations with Friends</td>\n",
       "      <td>https://www.goodreads.com/review/show/1855355089</td>\n",
       "      <td>1855355089</td>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>2</td>\n",
       "      <td>Sam</td>\n",
       "      <td>/user/show/59357213-sam</td>\n",
       "      <td>I didn't really respond well to Conversations ...</td>\n",
       "      <td>1043</td>\n",
       "      <td>default</td>\n",
       "      <td>[2017-reads]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32187419-conversations-with-friends</td>\n",
       "      <td>32187419-conversations-with-friends</td>\n",
       "      <td>Conversations with Friends</td>\n",
       "      <td>https://www.goodreads.com/review/show/2098766690</td>\n",
       "      <td>2098766690</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>5</td>\n",
       "      <td>Jill</td>\n",
       "      <td>/user/show/2228181-jill</td>\n",
       "      <td>I’ve been thinking a lot about aging lately: t...</td>\n",
       "      <td>937</td>\n",
       "      <td>default</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32187419-conversations-with-friends</td>\n",
       "      <td>32187419-conversations-with-friends</td>\n",
       "      <td>Conversations with Friends</td>\n",
       "      <td>https://www.goodreads.com/review/show/1948088321</td>\n",
       "      <td>1948088321</td>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>3</td>\n",
       "      <td>Esil</td>\n",
       "      <td>/user/show/3643764-esil</td>\n",
       "      <td>A very tepid 3 stars. Conversations with Frien...</td>\n",
       "      <td>839</td>\n",
       "      <td>default</td>\n",
       "      <td>[netgalley]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32187419-conversations-with-friends</td>\n",
       "      <td>32187419-conversations-with-friends</td>\n",
       "      <td>Conversations with Friends</td>\n",
       "      <td>https://www.goodreads.com/review/show/2831723058</td>\n",
       "      <td>2831723058</td>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>5</td>\n",
       "      <td>emma</td>\n",
       "      <td>/user/show/32879029-emma</td>\n",
       "      <td>have been truly dealt a series of death blows ...</td>\n",
       "      <td>592</td>\n",
       "      <td>default</td>\n",
       "      <td>[couldn-t-wait-to-read, favorites, literary-fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32187419-conversations-with-friends</td>\n",
       "      <td>32187419-conversations-with-friends</td>\n",
       "      <td>Conversations with Friends</td>\n",
       "      <td>https://www.goodreads.com/review/show/2340296379</td>\n",
       "      <td>2340296379</td>\n",
       "      <td>2018-03-26</td>\n",
       "      <td>2</td>\n",
       "      <td>Barry Pierce</td>\n",
       "      <td>/user/show/4593541-barry-pierce</td>\n",
       "      <td>The narrator of Sally Rooney's Conversations w...</td>\n",
       "      <td>480</td>\n",
       "      <td>default</td>\n",
       "      <td>[21st-century, read-in-2018]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297450</th>\n",
       "      <td>54493401-project-hail-mary</td>\n",
       "      <td>54493401-project-hail-mary</td>\n",
       "      <td>Project Hail Mary</td>\n",
       "      <td>https://www.goodreads.com/review/show/3553164073</td>\n",
       "      <td>3553164073</td>\n",
       "      <td>2020-09-17</td>\n",
       "      <td>5</td>\n",
       "      <td>Jenna</td>\n",
       "      <td>/user/show/3536004-jenna</td>\n",
       "      <td>~~~~~~~~~~~~~~It's publication day!~~~~~~~~~~~...</td>\n",
       "      <td>158</td>\n",
       "      <td>default</td>\n",
       "      <td>[science-fiction, edelweiss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297451</th>\n",
       "      <td>54493401-project-hail-mary</td>\n",
       "      <td>54493401-project-hail-mary</td>\n",
       "      <td>Project Hail Mary</td>\n",
       "      <td>https://www.goodreads.com/review/show/3763008971</td>\n",
       "      <td>3763008971</td>\n",
       "      <td>2021-05-24</td>\n",
       "      <td>5</td>\n",
       "      <td>Bradley</td>\n",
       "      <td>/user/show/4213258-bradley</td>\n",
       "      <td>And we're back. I loved the Martian and I was ...</td>\n",
       "      <td>152</td>\n",
       "      <td>default</td>\n",
       "      <td>[fantasy, 2021-shelf, sci-fi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297452</th>\n",
       "      <td>54493401-project-hail-mary</td>\n",
       "      <td>54493401-project-hail-mary</td>\n",
       "      <td>Project Hail Mary</td>\n",
       "      <td>https://www.goodreads.com/review/show/4077397636</td>\n",
       "      <td>4077397636</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>5</td>\n",
       "      <td>Kevin Kuhn</td>\n",
       "      <td>/user/show/59568642-kevin-kuhn</td>\n",
       "      <td>Let’s start with this, I completely enjoyed th...</td>\n",
       "      <td>135</td>\n",
       "      <td>default</td>\n",
       "      <td>[science-fiction, favorites]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297453</th>\n",
       "      <td>54493401-project-hail-mary</td>\n",
       "      <td>54493401-project-hail-mary</td>\n",
       "      <td>Project Hail Mary</td>\n",
       "      <td>https://www.goodreads.com/review/show/3882968267</td>\n",
       "      <td>3882968267</td>\n",
       "      <td>2021-04-02</td>\n",
       "      <td>4</td>\n",
       "      <td>Kemper</td>\n",
       "      <td>/user/show/405390-kemper</td>\n",
       "      <td>I received a free advanced copy of this from N...</td>\n",
       "      <td>138</td>\n",
       "      <td>default</td>\n",
       "      <td>[arc, space, 2021, sci-fi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297454</th>\n",
       "      <td>54493401-project-hail-mary</td>\n",
       "      <td>54493401-project-hail-mary</td>\n",
       "      <td>Project Hail Mary</td>\n",
       "      <td>https://www.goodreads.com/review/show/3684297093</td>\n",
       "      <td>3684297093</td>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>5</td>\n",
       "      <td>Jenny Lawson</td>\n",
       "      <td>/user/show/7392404-jenny-lawson</td>\n",
       "      <td>I'm not entirely smart enough to understand al...</td>\n",
       "      <td>131</td>\n",
       "      <td>default</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297455 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              book_id_title  \\\n",
       "0       32187419-conversations-with-friends   \n",
       "1       32187419-conversations-with-friends   \n",
       "2       32187419-conversations-with-friends   \n",
       "3       32187419-conversations-with-friends   \n",
       "4       32187419-conversations-with-friends   \n",
       "...                                     ...   \n",
       "297450           54493401-project-hail-mary   \n",
       "297451           54493401-project-hail-mary   \n",
       "297452           54493401-project-hail-mary   \n",
       "297453           54493401-project-hail-mary   \n",
       "297454           54493401-project-hail-mary   \n",
       "\n",
       "                                    book_id                  book_title  \\\n",
       "0       32187419-conversations-with-friends  Conversations with Friends   \n",
       "1       32187419-conversations-with-friends  Conversations with Friends   \n",
       "2       32187419-conversations-with-friends  Conversations with Friends   \n",
       "3       32187419-conversations-with-friends  Conversations with Friends   \n",
       "4       32187419-conversations-with-friends  Conversations with Friends   \n",
       "...                                     ...                         ...   \n",
       "297450           54493401-project-hail-mary           Project Hail Mary   \n",
       "297451           54493401-project-hail-mary           Project Hail Mary   \n",
       "297452           54493401-project-hail-mary           Project Hail Mary   \n",
       "297453           54493401-project-hail-mary           Project Hail Mary   \n",
       "297454           54493401-project-hail-mary           Project Hail Mary   \n",
       "\n",
       "                                              review_url   review_id  \\\n",
       "0       https://www.goodreads.com/review/show/1855355089  1855355089   \n",
       "1       https://www.goodreads.com/review/show/2098766690  2098766690   \n",
       "2       https://www.goodreads.com/review/show/1948088321  1948088321   \n",
       "3       https://www.goodreads.com/review/show/2831723058  2831723058   \n",
       "4       https://www.goodreads.com/review/show/2340296379  2340296379   \n",
       "...                                                  ...         ...   \n",
       "297450  https://www.goodreads.com/review/show/3553164073  3553164073   \n",
       "297451  https://www.goodreads.com/review/show/3763008971  3763008971   \n",
       "297452  https://www.goodreads.com/review/show/4077397636  4077397636   \n",
       "297453  https://www.goodreads.com/review/show/3882968267  3882968267   \n",
       "297454  https://www.goodreads.com/review/show/3684297093  3684297093   \n",
       "\n",
       "             date rating     user_name                         user_url  \\\n",
       "0      2016-12-29      2           Sam          /user/show/59357213-sam   \n",
       "1      2017-08-23      5          Jill          /user/show/2228181-jill   \n",
       "2      2017-06-09      3          Esil          /user/show/3643764-esil   \n",
       "3      2019-05-23      5          emma         /user/show/32879029-emma   \n",
       "4      2018-03-26      2  Barry Pierce  /user/show/4593541-barry-pierce   \n",
       "...           ...    ...           ...                              ...   \n",
       "297450 2020-09-17      5         Jenna         /user/show/3536004-jenna   \n",
       "297451 2021-05-24      5       Bradley       /user/show/4213258-bradley   \n",
       "297452 2021-06-28      5    Kevin Kuhn   /user/show/59568642-kevin-kuhn   \n",
       "297453 2021-04-02      4        Kemper         /user/show/405390-kemper   \n",
       "297454 2020-12-08      5  Jenny Lawson  /user/show/7392404-jenny-lawson   \n",
       "\n",
       "                                                     text  num_likes  \\\n",
       "0       I didn't really respond well to Conversations ...       1043   \n",
       "1       I’ve been thinking a lot about aging lately: t...        937   \n",
       "2       A very tepid 3 stars. Conversations with Frien...        839   \n",
       "3       have been truly dealt a series of death blows ...        592   \n",
       "4       The narrator of Sally Rooney's Conversations w...        480   \n",
       "...                                                   ...        ...   \n",
       "297450  ~~~~~~~~~~~~~~It's publication day!~~~~~~~~~~~...        158   \n",
       "297451  And we're back. I loved the Martian and I was ...        152   \n",
       "297452  Let’s start with this, I completely enjoyed th...        135   \n",
       "297453  I received a free advanced copy of this from N...        138   \n",
       "297454  I'm not entirely smart enough to understand al...        131   \n",
       "\n",
       "       sort_order                                            shelves  \n",
       "0         default                                       [2017-reads]  \n",
       "1         default                                                 []  \n",
       "2         default                                        [netgalley]  \n",
       "3         default  [couldn-t-wait-to-read, favorites, literary-fi...  \n",
       "4         default                       [21st-century, read-in-2018]  \n",
       "...           ...                                                ...  \n",
       "297450    default                       [science-fiction, edelweiss]  \n",
       "297451    default                      [fantasy, 2021-shelf, sci-fi]  \n",
       "297452    default                       [science-fiction, favorites]  \n",
       "297453    default                         [arc, space, 2021, sci-fi]  \n",
       "297454    default                                                 []  \n",
       "\n",
       "[297455 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_json('book_reviews_folder/all_reviews.json')\n",
    "reviews_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d9279c439293cd56693e7c05115c53cbb1633ee63d7052d68a345e17a860490"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
